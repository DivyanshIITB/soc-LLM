{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0f8J1NgJiG9"
   },
   "source": [
    "# **LLM Model Initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dafFB1u_HRmm",
    "outputId": "79d8f98e-a72f-4163-ace6-e2341f62383d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.1)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl (72.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed bitsandbytes-0.46.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FKWluBNbHVu5"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get token from environment\n",
    "login(token=os.getenv(\"HF_TOKEN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369,
     "referenced_widgets": [
      "0e2adb82af7644ca8a7b293d6ff6e56f",
      "b44c864d41b046dc800bcd5bf482a710",
      "ef42ddd8333d458687c441f507dc44e2",
      "556022a7497743ea9fd0a4155c85b28d",
      "ef16b849f90f4e7eb70aa299024e751a",
      "d541722bdbda4907b7c006313f74255e",
      "6ee139a51ef84649a365ababfdf4ba3d",
      "8efeb4d91fa2475d8364c40608d6b6cd",
      "06f51c4e2b654ae787d7aad2507c5fa8",
      "ebc0decfc8654d08a67c852a75b6db7f",
      "917027b5a3f34ebdb9895f382ceb9685",
      "d669cf5384164b1d9a9587b857260259",
      "7b1b629e4ff4494f90020a56abbb8f8a",
      "66d51ad989594dad89bb7d382323158d",
      "3fe03c125ec94106851707a7fddd71c8",
      "9e45b7f1479c4eaa85c8b71d0dbfb3d5",
      "1d9ce29140f14b3681a2f1af75ff2cfc",
      "518ec4e4d2b2476d873998d69798c6a3",
      "6387a2588b6e4b268a2a8a700690c674",
      "3137c9c47aa446099ee4b82758b93b24",
      "30fdeb7fac2648d7b461a5fbb3d2eaef",
      "0675f72ca9bc415090f5d486e7098fe3",
      "87c2a9cf73954ec6bdad6d6c507f7bea",
      "4fd52b9f5e154fc38324d3f842b05840",
      "2735f112d8e2404a860c3c0fd13b88eb",
      "ceea6abba73a4c4aa191f6961867db92",
      "5d86d28267df4ef9af1458bc644a4b28",
      "d9708d4243ef47b1862be92f6e695df7",
      "82440897996349f19af343f84e531def",
      "50c1f720e9a04c839824f4ac862753cc",
      "c8e44e1689e44171a78596d44bf2578b",
      "fc03efb3e7e84f57a367a374b5bcc75f",
      "0067d70d72d945f4a3ad3c4c94bbb7d6",
      "3b40770e435642e586a4e3cd14ef8af8",
      "ec0fe672d1e146968186ff8d37b25c12",
      "0561d02e7a664be299ac85316971ed03",
      "461ccab4ae0d4ef88f5cc7ddc7c1cd0e",
      "986b0e802ff549e78288247c4064c5dc",
      "9e4807c46f094bfb9e69d2e9faba6a9f",
      "a9cbf18ec2094016978bab816fd6ca87",
      "faf5bde5498042618c59581cc98a71ac",
      "e54932988b1f4155be118874c31cb718",
      "c4691e1a1f4743c69547ada4e11bb248",
      "ac741abaf9ca422b8341bfec8e0f0287",
      "1a5a44a638314d099d1352dd7fb6a7ec",
      "9ac8781a2dfa4bd8aa8880699c9d2f33",
      "bd5cd823c0f146f98d7041f5ed548a1e",
      "3a15fc92fa1c413d9b18971d942e9132",
      "7d88881b35a64f9b809c1dbc5e2972d6",
      "48022cca244d47feb794ef24df56032a",
      "def0e719fa394ff9bfba287f934a517a",
      "7543573cbf1f462a9e45d00d382a33b1",
      "c9fa116f68294f47be4fdf4248784a9b",
      "d1ca1a8c281649b4b83a69c855fde547",
      "139846ca519741b992995e4c3e096160",
      "d93549f2f12d45d7bec569e279aa868a",
      "53210e3815bc4508b7b092d5a007c8a0",
      "a26a44e6d591458c9cfa6c20907213a0",
      "d4ffc304fec54829a357d29594a96dda",
      "d024263cc30e45b682732997b7d4c985",
      "f3614c9987bc4073a9f7922281c49107",
      "8ec339417e7e4c62a08a480366edff75",
      "3675567e62a44ede9c71f9257175d9cb",
      "ffe84cdd16c1479bb5fdc699a4618194",
      "47d52f9d8f234323b0144f724f012260",
      "c331443f68af409290e597f8a6e5e5d2",
      "100c3807518c4e7491b56c4c80d1edf9",
      "e27687ade4bf4604b59ab2e1e625cd8b",
      "090cc92bfcb34c9c8f71e3ad75beccc1",
      "711e4a5ea9224b9984a34bcf571922b9",
      "01533abdffd941c3b2805b0e8c11fa92",
      "27bc85f871b24f8b883714c84a7f628c",
      "cb26bdae8ba64f428ea8a4c011ca3482",
      "376a2cee83b3445eb32e234d6776327e",
      "591205eec1fc4cf9b122557976835624",
      "67c960d7b9b74396ab273d447e137dd6",
      "d3ff3ad3ba2345fc83b31930d3b8946b",
      "2efdd995dbc249358c4c3d42cfca68b6",
      "4da77959729c4aa193fda3feb1891e65",
      "ab1089bf08f24909b82615a75939d769",
      "af37e14799364f68a68e60ba412ecb5d",
      "81fec22c851a466aa3daba7004e3d86e",
      "df1440e19ffd423eaf3afd64196b3573",
      "2d0faf9d2dc44ef290f38ec48171a99c",
      "d73b6f694c39409eb43bfc5638ac337e",
      "a2bb721fcf5c42478b99bf4bebabb197",
      "f08b35a3776c43abbf879a201ca3624a",
      "a58271ed39b04d46aeaefbefb12ef88e",
      "b83e595c8cae48d18aab1ed1db7ae496",
      "71e910435ad0479bb78a0cbd6f8181b9",
      "72e20ff462254cb68bf1e56b4a623141",
      "a54a8e276bcd422ba3a9d791f5877681",
      "d6768ec47454499088885531911afbf8",
      "39c6b117c71a47d5929e4b0abbb4e6cf",
      "44f29cbfe3d14eed84cd3aaef88ab865",
      "2507fe2e18ca48a8bb875469659bc2c8",
      "0f22ffe6676e450ea2f7ac37584cd351",
      "e8b7ebc7bdc14838bab79d821a02a05e",
      "12b746089cd54ad4beea345826f7d09d",
      "10ced90e876e4da18a6a9c983daa2b28",
      "67bd7af523324da699cff78baab7bfac",
      "42eeb9a156514696be8dd34793f8c4b6",
      "ef4467152700405bbe06dc19ed0d0a73",
      "0bfa38ad1c46410abcef0d012837a972",
      "b7f070e3546e45ed92f209dbfd01fe30",
      "7f75627d7906426b8bd39cf5f8fc6ef1",
      "d9a58b4949774b948332c4aaa7078cd5",
      "37adadf40e7b4ca5b72060d225ab22c6",
      "6778b58913c54665aa37a6e5ec51733f",
      "f046b3ff3fe544398e9e18ea5b401324",
      "e230f08a20fd45b7b95f39226506504b",
      "979fd5d1a1bb45de8ee2c0d4a3c22a0d",
      "f5736303df104367aee6e336dbfe2aaa",
      "6c9910dcaed0428b80f692c3cd25604e",
      "fb83ca4e740444098eef8b6acf24b1b0",
      "92522892333242cd85cb0579c105dbb1",
      "11f2c24588464baca1ff6dd177ddf36b",
      "ec0aa565b6e6484a8d4beb79e5eb740a",
      "bcaa07abea244298a3b810a1aa9bdd9f",
      "df6a31f8ba7e42b6b1f9ff6a6c4e27c4",
      "aa8710def38b466ca420b77e088313fd"
     ]
    },
    "id": "k7GnF2t1HdOr",
    "outputId": "683d3a65-ae94-4aab-e6dc-9817ea4662b7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e2adb82af7644ca8a7b293d6ff6e56f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d669cf5384164b1d9a9587b857260259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c2a9cf73954ec6bdad6d6c507f7bea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b40770e435642e586a4e3cd14ef8af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a5a44a638314d099d1352dd7fb6a7ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93549f2f12d45d7bec569e279aa868a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "100c3807518c4e7491b56c4c80d1edf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2efdd995dbc249358c4c3d42cfca68b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b83e595c8cae48d18aab1ed1db7ae496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10ced90e876e4da18a6a9c983daa2b28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e230f08a20fd45b7b95f39226506504b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load model with automatic device mapping and efficient precision\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",           # Automatically assigns to GPU if available\n",
    "    torch_dtype=\"auto\",          # Uses float16/bfloat16 if supported\n",
    "    low_cpu_mem_usage=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p8KUqKQbHfoU",
    "outputId": "cce9c21e-738d-4bf1-8646-9679960f5aba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "chatbot = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    do_sample=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NWhlXhUJHlRz",
    "outputId": "6a80d85d-1ed1-445c-bfdb-244c7b1377f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an academic assistant for undergraduate students. Answer the following question using only official university guidelines.\n",
      "\n",
      "Q: What is the minimum CPI required for branch change?\n",
      "A: According to university guidelines, the minimum CPI required for a branch change is 2.0. This means that a student must have a cumulative grade point average (CPI) of at least 2.0 in order to change their branch. It is important to note that this requirement may vary depending on the faculty or program, so it is best to consult with an academic advisor for more information.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"You are an academic assistant for undergraduate students. Answer the following question using only official university guidelines.\n",
    "\n",
    "Q: What is the minimum CPI required for branch change?\n",
    "A:\"\"\"\n",
    "\n",
    "response = chatbot(prompt)\n",
    "print(response[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5CAbZAsJVdG"
   },
   "source": [
    "# **PDF Loading and Parsing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Taecy8SqJUC3",
    "outputId": "43155eb7-53ad-4084-9427-85fd012c8dcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e71s0kvCTml2",
    "outputId": "b55fd183-6463-4879-ccb8-1c793bcd51cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      " \n",
      " \n",
      "INDIAN INSTITUTE OF TECHNOLOGY BOMBAY \n",
      " \n",
      " \n",
      "Rules & Regulations  \n",
      "for Undergraduate Programmes \n",
      " \n",
      " \n",
      " \n",
      "Applicable to the B.Tech., B.S., B.Des.,   \n",
      "Dual Degree students admitted from the  \n",
      "Academic Year 2007 - 2008 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Updated: January, 2025  \n",
      "2                                      \n",
      "Move to Index \n",
      "Rules are classified into three separate categories as follows: (I) those which may be implemented \n",
      "within a department by DUGC/DPGC, (ii) those that require a decision at the level of Associate/ Dean \n",
      "Academic Progamme or UGAPEC/PGAPEC, based on recommendations from the department bodies \n",
      "(iii) those that need to be discussed in the Senate for a decision. \n",
      " \n",
      "Therefore, rules are colored with one of three colors. \n",
      "1. The color green indicates that the final authority for rule is the Convener DUGC \n",
      "2. The color yellow, and underlined means that the final authority is Associate Dean (Academic \n",
      "Programme)/ Dean (Academic Programme) \n",
      "3. The color yellow, without an underline\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    full_text = \"\"\n",
    "    for page in doc:\n",
    "        full_text += page.get_text()\n",
    "    doc.close()\n",
    "    return full_text\n",
    "\n",
    "pdf_path = \"ugrulebook.pdf\"\n",
    "\n",
    "# Extract full text\n",
    "document_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# Previewing first 1000 characters\n",
    "print(document_text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBQGk2M8VWKe"
   },
   "source": [
    "# **Text Splitter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "YO4mjNcvUTlq"
   },
   "outputs": [],
   "source": [
    "!pip install -q langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ptoP0srcVagK"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,       # Number of characters in each chunk\n",
    "    chunk_overlap=200,     # Overlap between chunks\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \"]\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_text(document_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8j6gU5FWPRv"
   },
   "source": [
    "# **Vector Database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "In_9Ir9QVnm0",
    "outputId": "089328db-c9e6-48aa-b0ac-2893b9961ad7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.68)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.26)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.4)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (4.14.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.7.9)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.3)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (2.33.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n",
      "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
      "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.1 langchain-community-0.3.27 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.10.1 python-dotenv-1.1.1 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -q faiss-cpu sentence-transformers langchain\n",
    "!pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424,
     "referenced_widgets": [
      "c4e41f559ee744fda1afd2dad7dc3228",
      "8cdf169cf238447ea8f3a99606e2a2d1",
      "9fc7e444e0884bf5a64f876e2079994d",
      "366e99a7edc841c28b4c178b419e3f0b",
      "52eb6ee7a7314a4daf6fce12c2f90987",
      "719a9031f1fa47569007a77ec2999c30",
      "76df47e55cbc43cfaaf0c1a4201f6f7b",
      "c6140814efbc4ea087bfa64606ae21d1",
      "71efa97d90444b67b8068aa49d3f7921",
      "e49193d7fe8c4f2998c00e86b270bc5f",
      "97f50abcd5464709b14252fc4888e112",
      "e18a342e0cf042c68d46ff6e2b13d221",
      "f5157e95655f496fb559aed2839e0930",
      "6bfcaf46d93e4b10a21a9922a98bdb7e",
      "d2cd5a638eef4ea9a92ae71bd244a557",
      "6b2a9d9b8b5c459784c1e968dfc3f144",
      "d7ad359e5d88490fb3cb871e733f4b38",
      "a5c4da068cb44f63bc7cb9d400a85cfb",
      "ee55ee34e5d645c88ca6fd68a2cfa1a5",
      "bc16e3d22f6d420fbd55addfa725ef7e",
      "a9e6d09df7034db8b1c3a3b8d1387e9a",
      "2a22a03aebb7422ab18c7c791540b60a",
      "8790028cd455430587f9286a5877125e",
      "761b6328363d4e40b9f7e8201b036777",
      "9df50043c6ad471d97f0470bcfd38d70",
      "ff68b2b1105349dc9909c14127980302",
      "6209bddbc48e404b8fee41243175d8d4",
      "873eab0b454d4a3e8c83d4ea6d6e67df",
      "adc44ef283ce45c4b3d20d60d2f75a4c",
      "5c5f568167fa43aea3af87f84223c54f",
      "de3ceb8bac944e0f9d708cdfa3a44916",
      "3a5670037c7d4f2592ec067bb4afaa17",
      "7fbce62e25da4a9186f0545b9a1ee4d8",
      "62743c19b4e240eaa574526030a3beef",
      "74c0ab6d25c84dc8bd6f41a3deac1789",
      "5e6a72d13b664ab98d0cacca603dbbee",
      "7c48ae2564fc493183eb9f9e9342dac3",
      "7e93a9f0361648fda64e5b767c038ef9",
      "84bc546938ad45e6b880dcf80cbc69ff",
      "15ace37c9c6a4666bf18a545bff2ce5c",
      "d9994241026143788b388874b18b04d2",
      "fbf8b2a5ad8042d0b14cbc8aa7889098",
      "4059253e68a64a76bd13c94afca2c2f3",
      "dddbb5bf04f940c38b76ddfd15a79a52",
      "cc61dda59bc349d2b3a65123d4c44f57",
      "f426a2998a8340c3a74af3d38527bc49",
      "3453786a189843f29d3472aa2c7491cb",
      "5fd24b5a36954ae1997631c4faef27a2",
      "78edbfe81d0643b889f6f350b30b8ea4",
      "8c107b2a7f3e4d50b1360894f8eb743e",
      "90d28a3388d84db7a80b614b128e3347",
      "d6f3ed5f497941dba1438738afcf4ab7",
      "3aed2d5a453a413691721d2bde25452a",
      "f5dac7a92afc4b15a334ff8bae6b3d78",
      "0cc49cd342c9466bb63151eb11e1b48c",
      "ac1f477f456445abb5a450a9a66e0f32",
      "0c9314bc92ae4e9f8af1eb9dcbd33f95",
      "2f5497a8e89348a99bb8baa16f0ea7a2",
      "36c34eb3d4894de0b5ef40f0520e71fc",
      "81204913a495467a8c1d9d179fad1d97",
      "523479a914b84fd191478b98fe2cdd25",
      "b1204c15c2b54dbcb85d141116544201",
      "8226baf4404b4a429b0bdc00d89d1704",
      "ff20c972b82c4f5ca0d9496a57b1c0fc",
      "26d625fbec994bbdbc9225147babe37e",
      "326c5df1877f4907bfb587d56ba3c762",
      "4462be1c0c5d44a89eef48df4c34c54d",
      "fc27b409b9b348b197e7a672f19ae83c",
      "d0d78098b7be4e84b825746b64a08b9b",
      "747c0adcac0e49fe86ea6f9150ca4497",
      "7efc2f844a3f404d908cd69d022d8dec",
      "07eb1ff04a8d49acad2117da52a0cc03",
      "4215fb4c01ca48c0bb763e9d68d019b3",
      "5dada012093f4e6d9e4efa9bc7f2070f",
      "c5825220112e4ed2990372b0bfeeb4ac",
      "88abe1d168c0426dac29464d135256de",
      "767b0b304a2e43f39a1237073c0fd8cd",
      "6bf8725fe36340788d1f6886de985d02",
      "0a1b66c0290148e9b6a09869efa7c5fd",
      "3d168ec7fb844dd690ae207eb8ff39e1",
      "96e9b763dcb94c778ef13c0dd67a5fe0",
      "dc988120e4be436b8ccd774f4277d7ff",
      "4e57530a83614a06961b0f6a01d819eb",
      "24a3429573f8440c8a377608a0f36557",
      "d9f454686745443da13c0901c53bcc09",
      "0d21fce5dbdb42cdbf4403ff98513d37",
      "3746db69542345b0ab3bbaa09600b4d2",
      "6590dbb29fb04b0baed8078c0f532782",
      "0e5ca5a5bc4a4eec95c5b58cd7e3e8ed",
      "0ad3d1ef177c4a7b9d2f6cc65ba49c78",
      "8d538aefd905494ebcbb97f11744ed4a",
      "a3e69773f55b4256867c983b57dbb0c2",
      "451cd2a90c654d0091b730122c268558",
      "a45e94d600494f8182e6b04979d980f1",
      "badf3839c0d54f99aa3ef2715cf663fd",
      "37e40dfd88514de99441f8e911e8dcd0",
      "5c5cae3acd5547aca73db6db687a748b",
      "9dc62a2638cd4e6aae340a0459352af8",
      "0da97f1c25a74c2fa10e4051091c6b15",
      "d969f914aae146d69a545f3bc8a85da9",
      "d6a3c0be6aad460d883a332ab47431cc",
      "3872784a6c064cfe8c5719c76f40531a",
      "eacd26d82c464d29adf83680f7f0cb01",
      "422ac3131f8c47f98e2139a307fbdd0c",
      "60e1b10c90264fab89e63d9f9544a594",
      "a3bcdd37cfe5468f9c58f7b9a4c07e9a",
      "82bfc12a326746d38a7ab14b32f9997e",
      "280bcf9efa2647208663c326988ba306",
      "27f34284be9f49c88ad4eb1a02d6cb98",
      "55613fa77f144f42892f924464263e93",
      "19d6836d74814a11aaef7f1d375bffba",
      "1ea096512b2146afb112f038b24c46c6",
      "782e8f0a31f64f4e8ff03e534a4f0f2f",
      "157fffc1edc44d678fd31b4d43362660",
      "15cfe3c0aa934b288c5068dc89fcd31e",
      "72d2d55a29e34580a8503d514cfb04b0",
      "f2688488bea64ea696e51efd7a54e100",
      "22994e6c495642aab07654f3011fa67d",
      "9b6dab97e25448a6a34b1f4e5b1ebe4c",
      "176d4c9315984b758be99eb465261e78",
      "c8bde3edca31400e802a165506cee1ba"
     ]
    },
    "id": "WXc-P02sW8hD",
    "outputId": "5b383d45-bbdd-4a01-dc7a-8cf5f9a9ee60"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-28-3934915596.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4e41f559ee744fda1afd2dad7dc3228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e18a342e0cf042c68d46ff6e2b13d221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8790028cd455430587f9286a5877125e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62743c19b4e240eaa574526030a3beef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc61dda59bc349d2b3a65123d4c44f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac1f477f456445abb5a450a9a66e0f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4462be1c0c5d44a89eef48df4c34c54d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf8725fe36340788d1f6886de985d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e5ca5a5bc4a4eec95c5b58cd7e3e8ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d969f914aae146d69a545f3bc8a85da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d6836d74814a11aaef7f1d375bffba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "vector_db = FAISS.from_texts(chunks, embedding_model)\n",
    "\n",
    "vector_db.save_local(\"faiss_index_ug_rulebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRs7u_mbXuCk"
   },
   "source": [
    "# **Searching and passing the context to the prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "if9n0YhzcyVg"
   },
   "outputs": [],
   "source": [
    "def build_prompt(context, question):\n",
    "    return f\"\"\"\n",
    "Answer the following question using **only** the information in the context below.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "6Rz81KYpXGaW"
   },
   "outputs": [],
   "source": [
    "def get_answer_from_pdf(query, k=3):\n",
    "    # Search top k relevant chunks\n",
    "    docs = vector_db.similarity_search(query, k=k)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "    prompt = build_prompt(context, query)\n",
    "\n",
    "    # Generate answer using LLaMA\n",
    "    response = chatbot(prompt)[0][\"generated_text\"]\n",
    "    if \"Answer:\" in response:\n",
    "        return response.split(\"Answer:\")[1].strip()\n",
    "    else:\n",
    "        return response.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUK0zJ48aHA4"
   },
   "source": [
    "# **Custom prompt passing to the model and processing the output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GCRKR1m2YdJL",
    "outputId": "fc6aefa5-1667-4ee1-ee93-7c954adab9b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the minimum CPI required for branch change?\n",
      "Answer:\n",
      " 9\n",
      "\n",
      "Explanation: According to the context, the minimum CPI required for branch change is 9. This is mentioned in the second set of criteria for valid requests for branch change, where the “Branch-Change-CPI” of the student is required to be at least 9.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the minimum CPI required for branch change?\"\n",
    "answer = get_answer_from_pdf(query)\n",
    "print(\"Query:\", query)\n",
    "print(\"Answer:\\n\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vG_NWmX4ZvY8"
   },
   "source": [
    "# **Displaying output using UI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "E30j2i7qZGlM"
   },
   "outputs": [],
   "source": [
    "!pip install -q gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "-1IyNF_9ag6w"
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def gradio_chatbot(query):\n",
    "    return get_answer_from_pdf(query)\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn = gradio_chatbot,\n",
    "    inputs = gr.Textbox(\n",
    "        lines = 2,\n",
    "        placeholder = \"Ask something from the UG Rulebook\"\n",
    "    ),\n",
    "    outputs = \"text\",\n",
    "    title = \"UG Rulebook Chatbot\",\n",
    "    description = \"Ask questions based on the UG Rulebook PDF\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 611
    },
    "id": "rKIuDHVfbUMt",
    "outputId": "efabf1eb-a274-4b03-d620-5bd6e5a365b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://be0630f27b3ddbdf5c.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://be0630f27b3ddbdf5c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4dqYyGcd4Vu"
   },
   "source": [
    "# **Evaluating LLM Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "yPoy36KEbdv8"
   },
   "outputs": [],
   "source": [
    "# Evaluation dataset\n",
    "eval_data = [\n",
    "    {\n",
    "        \"question\": \"How many credits are needed for a minor?\",\n",
    "        \"expected\": \"30 credits.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Can a dual degree student apply for a minor?\",\n",
    "        \"expected\": \"Yes.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What happens if you don’t complete 30 credits for a minor?\",\n",
    "        \"expected\": \"If you don’t complete 30 credits for a minor, the minor will not be awarded. However, the individual course credits earned will be reflected in the transcript.\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UIBAwSEFe1HT",
    "outputId": "ac354644-a778-4504-d5b5-40c8cc15faef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❓ Q: How many credits are needed for a minor?\n",
      "✅ Expected: 30 credits.\n",
      "🤖 Predicted: 30 credits\n",
      "\n",
      "Explanation: According to the information provided in the context, a minor requires 30 credits worth of additional courses.\n",
      "\n",
      "------------------------------------------------------------\n",
      "❓ Q: Can a dual degree student apply for a minor?\n",
      "✅ Expected: Yes.\n",
      "🤖 Predicted: Yes.\n",
      "\n",
      "------------------------------------------------------------\n",
      "❓ Q: What happens if you don’t complete 30 credits for a minor?\n",
      "✅ Expected: If you don’t complete 30 credits for a minor, the minor will not be awarded. However, the individual course credits earned will be reflected in the transcript.\n",
      "🤖 Predicted: If you don’t complete 30 credits for a minor, the minor will not be awarded. However, the individual course credits earned will be reflected in the transcript.\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for item in eval_data:\n",
    "    q = item[\"question\"]\n",
    "    expected = item[\"expected\"]\n",
    "    predicted = get_answer_from_pdf(q)\n",
    "    print(f\"❓ Q: {q}\")\n",
    "    print(f\"✅ Expected: {expected}\")\n",
    "    print(f\"🤖 Predicted: {predicted}\\n\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ntoip1ake7s_",
    "outputId": "ed582fbd-5eff-41b6-d1a4-2ecda487d3fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔢 Manual Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy Metric\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "correct = 0\n",
    "for item in eval_data:\n",
    "    pred = get_answer_from_pdf(item[\"question\"]).lower()\n",
    "    def is_similar(a, b, threshold=0.6):\n",
    "      return SequenceMatcher(None, a.lower(), b.lower()).ratio() > threshold\n",
    "    if is_similar(item[\"expected\"], pred):\n",
    "      correct += 1\n",
    "\n",
    "accuracy = correct / len(eval_data)\n",
    "print(f\"🔢 Manual Accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
