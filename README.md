## Week 1: Python & Core Libraries
- Gained hands-on experience with Python syntax and basic programming constructs.
- Learned NumPy for numerical computations, array operations, broadcasting, etc.
- Explored Pandas for data manipulation and analysis using Series and DataFrames.
- Used Matplotlib for visualizing data through line plots, bar charts, histograms, etc.
- Got introduced to PyTorch and its Tensor operations for deep learning workflows.

## Week 2: Natural Language Processing (NLP)
- Studied basic NLP concepts such as text cleaning, tokenization, and stopword removal.
- Practiced Regular Expressions (regex) for pattern-based text extraction.
- Explored word embeddings like Word2Vec and GloVe for representing text numerically.
- Performed basic sentiment analysis to classify text as positive or negative.
- Compared NLP libraries: NLTK (granular and academic) vs spaCy (production-ready and efficient).

## Week 3: Neural Networks & Optimizers
- Learned the structure and working of artificial neural networks (ANNs).
- Built and understood feedforward neural networks with activation functions like ReLU and Sigmoid.
- Studied Recurrent Neural Networks (RNNs) for sequential data processing.
- Explored optimizers such as SGD, Adam, and RMSprop for efficient training.
- Understood concepts of overfitting, regularization (like Dropout), and early stopping.

---

## Assignment 1: Digit Recognizer with PyTorch

### Objective
To build a digit classification model using PyTorch that predicts handwritten digits from the MNIST dataset.

### Tasks Completed
- **Data Loading:** Used `torchvision.datasets.MNIST` and `DataLoader` to prepare training and testing sets.
- **Model Definition:** Implemented a simple feedforward neural network with multiple linear layers and ReLU activations.
- **Training:** Trained using `CrossEntropyLoss` and the `Adam` optimize
